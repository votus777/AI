
TF - Config 

Mulit worker training에서는 당연하게도 여러 worker들이 일을 한다.
이 worker들 중 1명이 chef worker가 되어, 보통 0번째 worker, 추가적인 일을 한다.
체크포인트 저장, 텐서보드에 전달한 요약 파일 작성 등등 



Cluster : training set이 부분으로 나뉘어 각 worker에게 가는 정보 할당량

Task : 각 worker 들이 하게 될 작업 종류,타입 

ex) 앞서 말했듯이 chef worker는 좀 더 많을 일을 해야한다. 
    즉, 일반 worker들과 Task가 달라진다.  
    같은 Cluster를 받아도 맡은 역할에 따라 다른 Task를 하게 된다.  



tf.distribute.Strategy API에서 데이타셋을 자동으로 나눠준다. 그러나 이는 치우쳐진 batch를 만들 수도 있기에 
off로 돌릴 수도 있다. 대신 수동으로 각 worker에 배당되는 batch를 정할 수도 있다. 


NCCL은 Nvidia에서 나온거라 한다. 역시 Window 하고 안친하다. (Window에서는 저 옵션이 안돌아가서 에러 발생)

synchronous training : 모든 worker는 각자 다른 data slice를 배당받고 각 단계마다 가중치를 종합한다. 
asynchronous training : 모든 worker가 data를 가지고 각자 훈련한뒤 가중치 또한 독립적으로 갱신한다. 



tf.distribute.MirroredStrategy 

synchronous, 

